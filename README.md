

https://github.com/user-attachments/assets/858fb275-cdc0-4e8c-9907-a1f7ae9a9604


<h1 align="center" style="font-size: 3em;">ğŸ” Multimodal Deepfake Detection using Explainable AI</h1>

<p align="center">
An AI-powered system to detect manipulated media using audio-visual fusion and transparent explainability
</p>

---

## ğŸ“Œ Overview

Deepfake technology has made it increasingly difficult to trust digital media. This project introduces a **multimodal deepfake detection system** that analyzes both **video and audio inputs** to classify media as real or fake. To ensure transparency, **Explainable AI (XAI)** techniques are used to highlight manipulated regions and features.

---

## ğŸ¯ Problem Statement

The rise of AI-generated fake videos and voices has created serious threats in misinformation, fraud, and digital forensics. Most existing solutions are either single-modal or black-box models. This project addresses these challenges by combining **audio-visual analysis** with **interpretable deep learning**.

---

## ğŸš€ Key Features

* ğŸ¥ Video-based deepfake detection using CNNs
* ğŸ”Š Audio deepfake detection via spectrogram analysis
* ğŸ”— Multimodal fusion for higher accuracy
* ğŸ§  Explainable AI using Grad-CAM and saliency maps
* ğŸ“Š Confidence score with visual explanations
* ğŸŒ Scalable backend for real-world deployment

---

## ğŸ§  System Architecture

```
Video Input
   â†“
Frame & Audio Extraction
   â†“
Video CNN (Face Analysis)      Audio CNN (Spectrogram)
           â†“                    â†“
         Feature Fusion (Multimodal)
                    â†“
              Classification
                    â†“
           Explainable AI (XAI)
                    â†“
              Final Prediction
```

---

## âš™ï¸ Tech Stack

* **Language:** Python
* **Deep Learning:** PyTorch
* **Computer Vision:** OpenCV
* **Audio Processing:** Librosa
* **Explainability:** Grad-CAM, Saliency Maps
* **Backend:** Flask / FastAPI
* **Frontend:** HTML, CSS, JavaScript / React
* **Deployment:** AWS / Local

---

## ğŸ“‚ Project Structure

```
deepfake-detection/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ video/
â”‚   â””â”€â”€ audio/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ video_model.py
â”‚   â”œâ”€â”€ audio_model.py
â”‚   â””â”€â”€ fusion_model.py
â”‚
â”œâ”€â”€ explainability/
â”‚   â”œâ”€â”€ grad_cam.py
â”‚   â””â”€â”€ audio_saliency.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ frame_extraction.py
â”‚   â””â”€â”€ audio_extraction.py
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š Datasets Used

* **FaceForensics++** â€“ Video deepfake dataset
* **DFDC (Facebook Deepfake Detection Challenge)**
* **ASVspoof 2019** â€“ Audio deepfake dataset

> Due to large dataset sizes, only selected subsets are used.

---

## ğŸ§ª How It Works

1. User uploads a video file
2. Frames and audio are extracted
3. Video and audio models analyze inputs
4. Multimodal fusion combines predictions
5. Explainable AI highlights suspicious regions
6. Final result with confidence score is displayed

---

## ğŸ” Use Cases

* ğŸ“° Media and news verification
* âš–ï¸ Digital forensics and law enforcement
* ğŸ›¡ï¸ Fraud and identity protection
* ğŸ“± Social media content moderation
* ğŸ—³ï¸ Election and misinformation security

---

## ğŸ”® Future Enhancements

* Real-time deepfake detection
* Transformer-based video models
* Attention-based fusion techniques
* Browser and video-call integrations
* Cloud-based API service

---

## ğŸ‘©â€ğŸ’» Author

**Vanshika Saxena**
B.Tech Computer Science
AI & Machine Learning Enthusiast

---

## â­ Acknowledgements

* Open-source AI and ML community
* Research papers on deepfake detection
* Publicly available datasets

---

<p align="center">â­ If you find this project useful, consider giving it a star!</p>
